x-ollama-base: &ollama-base
    image: ollama/ollama:latest
    hostname: ollama
    privileged: true
    pull_policy: always
    tty: true
    ports:
      - 11434:11434
    ulimits:
      memlock: -1
    environment:
      - OLLAMA_FLASH_ATTENTION=true
      - OLLAMA_KV_CACHE_TYPE=q4_0
      - OLLAMA_SCHED_SPREAD=true
      - OLLAMA_NOHISTORY=true
      - OLLAMA_NOPRUNE=false
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_MAX_QUEUE=512
    volumes:
      - ./ollama:/root/.ollama
    healthcheck:
      test: ['CMD-SHELL', 'ollama --version && ollama ps || exit 1']
      start_period: 5s
      interval: 5s
      timeout: 5s
      retries: 10

x-flowise-base: &flowise-base
    image: flowiseai/flowise:latest
    hostname: flowise
    pull_policy: always
    environment:
      - PORT=3000
      - CORS_ORIGINS=*
      - DATABASE_PATH=/root/.flowise
      - DATABASE_SSL=false
      - APIKEY_PATH=/root/.flowise
      - SECRETKEY_PATH=/root/.flowise
      - LOG_PATH=/root/.flowise/logs
      - REDIS_URL=redis://redis:6379
      - FLOWISE_USERNAME=${FLOWISE_USERNAME}
      - FLOWISE_PASSWORD=${FLOWISE_PASSWORD}
      - DATABASE_TYPE=${DATABASE_TYPE}
      - DATABASE_HOST=${DATABASE_HOST}
      - DATABASE_PORT=${DATABASE_PORT}
      - DATABASE_USER=${DATABASE_USER}
      - DATABASE_PASSWORD=${DATABASE_PASSWORD}
      - DATABASE_NAME=${DATABASE_NAME}
    ports:
      - 3000:3000
    volumes:
      - ./flowise:/root/.flowise

x-openwebui-base: &openwebui-base
    image: ghcr.io/open-webui/open-webui:main
    hostname: open-webui
    pull_policy: always
    environment:
      - ENV=prod
      - CUSTOM_NAME=lab
      - WEBUI_NAME=lab
      - PORT=8080
      - ENABLE_ADMIN_CHAT_ACCESS=true
      - ENABLE_CHANNELS=true
      - DEFAULT_LOCALE=en
      - AIOHTTP_CLIENT_TIMEOUT=100
      - ENABLE_OLLAMA_API=true
      - OLLAMA_BASE_URL=http://ollama:11434
      - ENABLE_AUTOCOMPLETE_GENERATION=true
      - AUTOCOMPLETE_GENERATION_INPUT_MAX_LENGTH=-1
      - ENABLE_FORWARD_USER_INFO_HEADERS=false
      - ENABLE_RAG_LOCAL_WEB_FETCH=false
      - RESET_CONFIG_ON_START=false
      - SAFE_MODE=false
      - CORS_ALLOW_ORIGIN=*
      - RAG_EMBEDDING_MODEL_AUTO_UPDATE=true
      - RAG_RERANKING_MODEL_AUTO_UPDATE=true
      - WHISPER_MODEL_AUTO_UPDATE=true
      - RAG_EMBEDDING_ENGINE=ollama
      - RAG_EMBEDDING_MODEL=nomic-embed-text:latest
      - ENABLE_GOOGLE_DRIVE_INTEGRATION=false
      - GOOGLE_DRIVE_CLIENT_ID=
      - GOOGLE_DRIVE_API_KEY=
      - ENABLE_IMAGE_GENERATION=false
      - IMAGE_GENERATION_ENGINE=comfyui
      - IMAGE_GENERATION_MODEL=
      - IMAGE_SIZE=512x512
      - IMAGE_STEPS=50
      - COMFYUI_BASE_URL=
      - COMFYUI_API_KEY=
      - ENABLE_WEBSOCKET_SUPPORT=true
      - WEBSOCKET_MANAGER=redis
      - WEBSOCKET_REDIS_URL=redis://redis:6379/1
      - REDIS_URL=redis://redis:6379/1
      - ENABLE_RAG_WEB_SEARCH=true
      - ENABLE_SEARCH_QUERY_GENERATION=true
      - RAG_WEB_SEARCH_RESULT_COUNT=3
      - RAG_WEB_SEARCH_CONCURRENT_REQUESTS=3
      - ENABLE_OPENAI_API=${ENABLE_OPENAI_API}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - RAG_WEB_SEARCH_ENGINE=${RAG_WEB_SEARCH_ENGINE}
      - BRAVE_SEARCH_API_KEY=${BRAVE_SEARCH_API_KEY}
    ports:
      - 4000:8080
    extra_hosts:
      - host.docker.internal:host-gateway
    volumes:
      - ./openwebui:/app/backend/data

x-n8n-base: &n8n-base
    image: n8nio/n8n:latest
    hostname: n8n
    pull_policy: always
    environment:
      - N8N_DIAGNOSTICS_ENABLED=false
      - N8N_PERSONALIZATION_ENABLED=false
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true
      - EXECUTIONS_DATA_PRUNE=true
      - EXECUTIONS_DATA_MAX_AGE=168
      - EXECUTIONS_DATA_PRUNE_MAX_COUNT=50000
      - N8N_SECURE_COOKIE=false
      - N8N_QUEUE_TYPE=redis
      - N8N_QUEUE_HOST=redis
      - N8N_QUEUE_PORT=6379
      - N8N_QUEUE_NAME=n8n
      - DB_TYPE=${DB_TYPE}
      - DB_POSTGRESDB_HOST=${DB_POSTGRESDB_HOST}
      - DB_POSTGRESDB_PORT=${DB_POSTGRESDB_PORT}
      - DB_POSTGRESDB_DATABASE=${DB_POSTGRESDB_DATABASE}
      - DB_POSTGRESDB_USER=${DB_POSTGRESDB_USER}
      - DB_POSTGRESDB_PASSWORD=${DB_POSTGRESDB_PASSWORD}
    ports:
      - 5678:5678
    volumes:
      - ./n8n/storage:/home/node/.n8n
      - ./n8n/backup:/backup
      - ./n8n/shared:/data/shared

x-langflow-base: &langflow-base
    image: langflowai/langflow:latest
    hostname: langflow
    pull_policy: always
    ports:
      - 7860:7860
    environment:
      - LANGFLOW_AUTO_LOGIN=false
      - LANGFLOW_AUTO_SAVING=true
      - LANGFLOW_AUTO_SAVING_INTERVAL=1000
      - LANGFLOW_PORT=7860
      - LANGFLOW_PROMETHEUS_ENABLED=false
      - LANGFLOW_SUPERUSER=${LANGFLOW_SUPERUSER}
      - LANGFLOW_SUPERUSER_PASSWORD=${LANGFLOW_SUPERUSER_PASSWORD}
    volumes:
      - ./langflow:/app/langflow

x-anythingllm-base: &anythingllm-base
    image: mintplexlabs/anythingllm
    hostname: anythingllm
    pull_policy: always
    ports:
      - 3001:3001
    cap_add:
      - SYS_ADMIN
    environment:
      - STORAGE_DIR=/app/server/storage
      - SERVER_PORT=${SERVER_PORT}
      - UID=${UID}
      - GID=${GID}
      - LLM_PROVIDER=${LLM_PROVIDER}
      - OLLAMA_BASE_PATH=${OLLAMA_BASE_PATH}
      - OLLAMA_MODEL_PREF=${OLLAMA_MODEL_PREF}
      - OLLAMA_MODEL_TOKEN_LIMIT=${OLLAMA_MODEL_TOKEN_LIMIT}
      - OPEN_AI_KEY=${OPEN_AI_KEY}
      - OPEN_MODEL_PREF=${OPEN_MODEL_PREF}
      - EMBEDDING_ENGINE=${EMBEDDING_ENGINE}
      - EMBEDDING_BASE_PATH=${EMBEDDING_BASE_PATH}
      - EMBEDDING_MODEL_PREF=${EMBEDDING_MODEL_PREF}
      - EMBEDDING_MODEL_MAX_CHUNK_LENGTH=${EMBEDDING_MODEL_MAX_CHUNK_LENGTH}
      - PASSWORDMINCHAR=${PASSWORDMINCHAR}
      - PASSWORDMAXCHAR=${PASSWORDMAXCHAR}
      - PASSWORDLOWERCASE=${PASSWORDLOWERCASE}
      - PASSWORDUPPERCASE=${PASSWORDUPPERCASE}
      - PASSWORDNUMERIC=${PASSWORDNUMERIC}
      - PASSWORDSYMBOL=${PASSWORDSYMBOL}
      - PASSWORDREQUIREMENTS=${PASSWORDREQUIREMENTS}
      - VECTOR_DB=${VECTOR_DB}
      - CHROMA_ENDPOINT=${CHROMA_ENDPOINT}
    volumes:
      - ./anythingllm:/app/server/storage

x-postgres-base: &postgres-base
    image: postgres:latest
    hostname: postgres
    pull_policy: always
    volumes:
      - ./postgres:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -h localhost -U user -d lab']
      start_period: 5s
      interval: 5s
      timeout: 5s
      retries: 10

x-redis-base: &redis-base
    image: redislabs/redismod:latest
    hostname: redis
    pull_policy: always
    environment:
      - REDIS_PORT=6379
      - REDIS_DATABASES=16
      - REDIS_ARGS=--save 20 1
    volumes:
      - ./redis:/data
    healthcheck:
      test: ["CMD", "redis-cli","ping"]
      start_period: 5s
      interval: 1s
      timeout: 3s
      retries: 5

x-chroma-base: &chroma-base
    image: chromadb/chroma:latest
    hostname: chroma
    pull_policy: always
    volumes:
      - ./chroma:/chroma/chroma
    healthcheck:
      test: [ "CMD", "/bin/bash", "-c", "cat < /dev/null > /dev/tcp/localhost/8000" ]
      start_period: 5s
      interval: 30s
      timeout: 10s
      retries: 3

################################################

services:
    ollama-nvidia:
        <<: *ollama-base
        profiles:
          - nvidia
        container_name: ollama
        environment:
          - NVIDIA_VISIBLE_DEVICES=all
          - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
        runtime: nvidia
        deploy:
          resources:
            reservations:
              devices:
                - driver: nvidia
                  count: all
                  capabilities: [gpu]

    flowise-nvidia:
        <<: *flowise-base
        profiles:
          - nvidia
        container_name: flowise
        links:
          - redis-nvidia
        depends_on:
          - redis-nvidia

    openwebui-nvidia:
        <<: *openwebui-base
        profiles:
          - nvidia
        container_name: openwebui
        links:
          - redis-nvidia
        depends_on:
          - ollama-nvidia
          - redis-nvidia

    n8n-nvidia:
        <<: *n8n-base
        profiles:
          - nvidia
        container_name: n8n
        links:
          - redis-nvidia
        depends_on:
          - postgres-nvidia
          - redis-nvidia

    langflow-nvidia:
        <<: *langflow-base
        profiles:
          - nvidia
        container_name: langflow

    anythingllm-nvidia:
        <<: *anythingllm-base
        profiles:
          - nvidia
        container_name: anythingllm

    postgres-nvidia:
        <<: *postgres-base
        profiles:
          - nvidia
        container_name: postgres

    redis-nvidia:
        <<: *redis-base
        profiles:
          - nvidia
        container_name: redis

    chroma-nvidia:
        <<: *chroma-base
        profiles:
          - nvidia
        container_name: chroma

################################################

    ollama-others:
        <<: *ollama-base
        profiles:
          - others
        container_name: ollama

    flowise-others:
        <<: *flowise-base
        profiles:
          - others
        container_name: flowise
        links:
          - redis-others
        depends_on:
          - redis-others

    openwebui-others:
        <<: *openwebui-base
        profiles:
          - others
        container_name: openwebui
        links:
          - redis-others
        depends_on:
          - ollama-others
          - redis-others

    n8n-others:
        <<: *n8n-base
        profiles:
          - others
        container_name: n8n
        links:
          - redis-others
        depends_on:
          - postgres-others
          - redis-others

    langflow-others:
        <<: *langflow-base
        profiles:
          - others
        container_name: langflow

    anythingllm-others:
        <<: *anythingllm-base
        profiles:
          - others
        container_name: anythingllm

    postgres-others:
        <<: *postgres-base
        profiles:
          - others
        container_name: postgres

    redis-others:
        <<: *redis-base
        profiles:
          - others
        container_name: redis

    chroma-others:
        <<: *chroma-base
        profiles:
          - others
        container_name: chroma
