services:
  ollama:
    image: ollama/ollama:latest
    hostname: ollama
    container_name: ollama
    privileged: true
    pull_policy: always
    runtime: nvidia
    tty: true
    ulimits:
      memlock: -1
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
      - OLLAMA_FLASH_ATTENTION=true
      - OLLAMA_KV_CACHE_TYPE=q4_0
      - OLLAMA_SCHED_SPREAD=true
      - OLLAMA_NOHISTORY=true
      - OLLAMA_NOPRUNE=false
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_MAX_QUEUE=512
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ./ollama:/root/.ollama
    healthcheck:
      test: ['CMD-SHELL', 'ollama --version && ollama ps || exit 1']
      interval: 5s
      timeout: 5s
      retries: 10

  flowise:
    image: flowiseai/flowise:latest
    hostname: flowise
    container_name: flowise
    pull_policy: always
    environment:
      - PORT=3000
      - FLOWISE_USERNAME=user
      - FLOWISE_PASSWORD=1234
      - CORS_ORIGINS=*
      - DATABASE_TYPE=postgres
      - DATABASE_PATH=/root/.flowise
      - DATABASE_HOST=postgres
      - DATABASE_PORT=5432
      - DATABASE_USER=user
      - DATABASE_PASSWORD=KrFgLvKJRvinkEG5
      - DATABASE_NAME=lab
      - DATABASE_SSL=false
      - APIKEY_PATH=/root/.flowise
      - SECRETKEY_PATH=/root/.flowise
      - LOG_PATH=/root/.flowise/logs
      - REDIS_URL=redis://redis:6379
    ports:
      - 3000:3000
    links:
      - redis
    depends_on:
      - ollama
      - redis
    volumes:
      - ./flowise:/root/.flowise

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    hostname: open-webui
    container_name: open-webui
    pull_policy: always
    environment:
      - ENV=prod
      - CUSTOM_NAME=lab
      - WEBUI_NAME=lab
      - PORT=8080
      - ENABLE_ADMIN_CHAT_ACCESS=true
      - ENABLE_CHANNELS=true
      - DEFAULT_LOCALE=en
      - USE_CUDA_DOCKER=true
      - AIOHTTP_CLIENT_TIMEOUT=100
      - ENABLE_OLLAMA_API=true
      - OLLAMA_BASE_URL=http://ollama:11434
      - ENABLE_OPENAI_API=false
      #- OPENAI_API_KEY=sk-124781258123
      - ENABLE_AUTOCOMPLETE_GENERATION=true
      - AUTOCOMPLETE_GENERATION_INPUT_MAX_LENGTH=-1
      - ENABLE_FORWARD_USER_INFO_HEADERS=false
      - ENABLE_RAG_LOCAL_WEB_FETCH=false
      - RESET_CONFIG_ON_START=false
      - SAFE_MODE=false
      - CORS_ALLOW_ORIGIN=*
      - RAG_EMBEDDING_MODEL_AUTO_UPDATE=true
      - RAG_RERANKING_MODEL_AUTO_UPDATE=true
      - WHISPER_MODEL_AUTO_UPDATE=true
      - RAG_EMBEDDING_ENGINE=ollama
      - RAG_EMBEDDING_MODEL=nomic-embed-text:latest
      - ENABLE_GOOGLE_DRIVE_INTEGRATION=false
      - GOOGLE_DRIVE_CLIENT_ID=
      - GOOGLE_DRIVE_API_KEY=
      - ENABLE_IMAGE_GENERATION=false
      - IMAGE_GENERATION_ENGINE=comfyui
      - IMAGE_GENERATION_MODEL=
      - IMAGE_SIZE=512x512
      - IMAGE_STEPS=50
      - COMFYUI_BASE_URL=
      - COMFYUI_API_KEY=
      - ENABLE_WEBSOCKET_SUPPORT=true
      - WEBSOCKET_MANAGER=redis
      - WEBSOCKET_REDIS_URL=redis://redis:6379/1
      - REDIS_URL=redis://redis:6379/1
      - ENABLE_RAG_WEB_SEARCH=true
      - ENABLE_SEARCH_QUERY_GENERATION=true
      - RAG_WEB_SEARCH_RESULT_COUNT=3
      - RAG_WEB_SEARCH_CONCURRENT_REQUESTS=3
      - RAG_WEB_SEARCH_ENGINE=brave
      - BRAVE_SEARCH_API_KEY=
    ports:
      - 4000:8080
    extra_hosts:
      - host.docker.internal:host-gateway
    links:
      - redis
    depends_on:
      - ollama
      - redis
    volumes:
      - ./openwebui:/app/backend/data

  n8n:
    image: n8nio/n8n:latest
    hostname: n8n
    container_name: n8n
    pull_policy: always
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=lab
      - DB_POSTGRESDB_USER=user
      - DB_POSTGRESDB_PASSWORD=KrFgLvKJRvinkEG5
      - N8N_DIAGNOSTICS_ENABLED=false
      - N8N_PERSONALIZATION_ENABLED=false
      - EXECUTIONS_DATA_PRUNE=true
      - EXECUTIONS_DATA_MAX_AGE=168
      - EXECUTIONS_DATA_PRUNE_MAX_COUNT=50000
      - N8N_SECURE_COOKIE=false
    ports:
      - 5678:5678
    volumes:
      - ./n8n/storage:/home/node/.n8n
      - ./n8n/backup:/backup
      - ./n8n/shared:/data/shared
    depends_on:
      postgres:
        condition: service_healthy

  langflow:
    image: langflowai/langflow:latest
    hostname: langflow
    container_name: langflow
    restart: always
    ports:
      - 7860:7860
    environment:
      - LANGFLOW_AUTO_LOGIN=false
      - LANGFLOW_SUPERUSER=user
      - LANGFLOW_SUPERUSER_PASSWORD=123456
      - LANGFLOW_AUTO_SAVING=true
      - LANGFLOW_AUTO_SAVING_INTERVAL=1000
      - LANGFLOW_PORT=7860
      - LANGFLOW_PROMETHEUS_ENABLED=false
    depends_on:
      - ollama
    volumes:
      - ./langflow:/app/langflow

  postgres:
    image: postgres:latest
    hostname: postgres
    container_name: postgres
    pull_policy: always
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=KrFgLvKJRvinkEG5
      - POSTGRES_DB=lab
    volumes:
      - ./postgres:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -h localhost -U user -d lab']
      interval: 5s
      timeout: 5s
      retries: 10

  redis:
    image: redislabs/redismod:latest
    hostname: redis
    container_name: redis
    pull_policy: always
    environment:
      - REDIS_PORT=6379
      - REDIS_DATABASES=16
      - REDIS_ARGS=--save 20 1
    volumes: 
      - ./redis:/data
    healthcheck:
      test: ["CMD", "redis-cli","ping"]
      start_period: 5s
      interval: 1s
      timeout: 3s
      retries: 5

#  langfuse:
#    image: ghcr.io/langfuse/langfuse:latest
#    hostname: langfuse
#    container_name: langfuse
#    pull_policy: always
#    depends_on:
#      - postgres
#      - flowise
#    ports:
#      - 5000:3000
#    environment:
#      - NODE_ENV=production
#      - DATABASE_URL=postgresql://user:KrFgLvKJRvinkEG5@postgres:5432/lab
#      - NEXTAUTH_SECRET=mysecret
#      - SALT=mysalt
#      - NEXTAUTH_URL=http://localhost:4000
#      - TELEMETRY_ENABLED=${TELEMETRY_ENABLED:-true}
#      - NEXT_PUBLIC_SIGN_UP_DISABLED=${NEXT_PUBLIC_SIGN_UP_DISABLED:-false}
#      - LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES=${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-false}
